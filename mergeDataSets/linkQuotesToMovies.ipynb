{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link quotebank and our movie dataset\n",
    "Once again we chose not to upload the Quotebank datasets we use on github because they were too big ; this notebook filters the quotes to only keep those whose author appears in `movie_data_2015_2020.csv`.\n",
    "\n",
    "The two data sources are:\n",
    "- the **QuoteBank datasets** [link](https://zenodo.org/record/4277311) from the year 2015 to 2020 (quotation-centric versions), that have to be downloaded and put in the `data` folder. They contain quotes along with a list of potential authors and their probabilities.\n",
    "- our own **movie dataset** extracted in `movieProcessing`.\n",
    "\n",
    "The initial architecture to run this notebook should be the following:\n",
    "```\n",
    "    .\n",
    "    ├── mergeDataSets\n",
    "    │   └── link_quotes_to_movies.ipynb   # this notebook \n",
    "    └── data/                             # the datasets we need\n",
    "        ├── movie_data_2015_2020.csv      # from the moviePreprocessing notebook\n",
    "        ├── quotes-2015.json.bz2\n",
    "        ├── quotes-2016.json.bz2\n",
    "        ├── quotes-2017.json.bz2\n",
    "        ├── quotes-2018.json.bz2\n",
    "        ├── quotes-2019.json.bz2\n",
    "        └── quotes-2020.json.bz2\n",
    "```\n",
    "where each quotes files comes from the quotation-centric version of the QuoteBank datasets, described at the link above.\n",
    "\n",
    "We simply link the quotes to the actors and crew members from our movie dataset, using the most probable author.\n",
    "\n",
    "**The goal of this notebook is to generate datasets containing the filtered quotes. These datasets will be named `movie_{year}_crew_quotes.csv.gz` (where `{year}` is the year the quote was made) and located in the `data` folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import datetime\n",
    "\n",
    "# Constants to easily update and read the code\n",
    "DATA_DIR = \"../data/\"\n",
    "MOVIE_DATASET = \"movie_data_2015_2020.csv\"\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2020\n",
    "YEARS = range(START_YEAR, END_YEAR + 1)\n",
    "\n",
    "# Auxiliary functions\n",
    "def quotes_dataset(year):\n",
    "    return f'quotes-{year}.json.bz2'\n",
    "\n",
    "def output_dataset(year):\n",
    "    return f\"movie_{year}_crew_quotes.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>ordering_y</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt1179933</td>\n",
       "      <td>movie</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Action,Drama,Horror</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nm6618222</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lindsey Weber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer</td>\n",
       "      <td>tt4530422,tt2660888,tt2548396,tt1179933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt4530422</td>\n",
       "      <td>movie</td>\n",
       "      <td>Overlord</td>\n",
       "      <td>Overlord</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Action,Horror,Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>nm6618222</td>\n",
       "      <td>producer</td>\n",
       "      <td>producer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lindsey Weber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>producer</td>\n",
       "      <td>tt4530422,tt2660888,tt2548396,tt1179933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt1179933</td>\n",
       "      <td>movie</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>Action,Drama,Horror</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nm0000422</td>\n",
       "      <td>actor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Howard\"]</td>\n",
       "      <td>John Goodman</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor,soundtrack,producer</td>\n",
       "      <td>tt0101410,tt1179933,tt1024648,tt1907668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt2406566</td>\n",
       "      <td>movie</td>\n",
       "      <td>Atomic Blonde</td>\n",
       "      <td>Atomic Blonde</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Action,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nm0000422</td>\n",
       "      <td>actor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Emmett Kurzfeld\"]</td>\n",
       "      <td>John Goodman</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor,soundtrack,producer</td>\n",
       "      <td>tt0101410,tt1179933,tt1024648,tt1907668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt5968394</td>\n",
       "      <td>movie</td>\n",
       "      <td>Captive State</td>\n",
       "      <td>Captive State</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Action,Horror,Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nm0000422</td>\n",
       "      <td>actor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"William Mulligan\"]</td>\n",
       "      <td>John Goodman</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actor,soundtrack,producer</td>\n",
       "      <td>tt0101410,tt1179933,tt1024648,tt1907668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     tconst titleType         primaryTitle        originalTitle  \\\n",
       "0           0  tt1179933     movie  10 Cloverfield Lane  10 Cloverfield Lane   \n",
       "1           1  tt4530422     movie             Overlord             Overlord   \n",
       "2           2  tt1179933     movie  10 Cloverfield Lane  10 Cloverfield Lane   \n",
       "3           3  tt2406566     movie        Atomic Blonde        Atomic Blonde   \n",
       "4           4  tt5968394     movie        Captive State        Captive State   \n",
       "\n",
       "   isAdult  startYear  endYear  runtimeMinutes                genres  ...  \\\n",
       "0      0.0     2016.0      NaN           103.0   Action,Drama,Horror  ...   \n",
       "1      0.0     2018.0      NaN           110.0  Action,Horror,Sci-Fi  ...   \n",
       "2      0.0     2016.0      NaN           103.0   Action,Drama,Horror  ...   \n",
       "3      0.0     2017.0      NaN           115.0       Action,Thriller  ...   \n",
       "4      0.0     2019.0      NaN           109.0  Action,Horror,Sci-Fi  ...   \n",
       "\n",
       "  ordering_y     nconst  category       job            characters  \\\n",
       "0       10.0  nm6618222  producer  producer                   NaN   \n",
       "1        9.0  nm6618222  producer  producer                   NaN   \n",
       "2        1.0  nm0000422     actor       NaN            [\"Howard\"]   \n",
       "3        3.0  nm0000422     actor       NaN   [\"Emmett Kurzfeld\"]   \n",
       "4        1.0  nm0000422     actor       NaN  [\"William Mulligan\"]   \n",
       "\n",
       "     primaryName birthYear  deathYear          primaryProfession  \\\n",
       "0  Lindsey Weber       NaN        NaN                   producer   \n",
       "1  Lindsey Weber       NaN        NaN                   producer   \n",
       "2   John Goodman    1952.0        NaN  actor,soundtrack,producer   \n",
       "3   John Goodman    1952.0        NaN  actor,soundtrack,producer   \n",
       "4   John Goodman    1952.0        NaN  actor,soundtrack,producer   \n",
       "\n",
       "                            knownForTitles  \n",
       "0  tt4530422,tt2660888,tt2548396,tt1179933  \n",
       "1  tt4530422,tt2660888,tt2548396,tt1179933  \n",
       "2  tt0101410,tt1179933,tt1024648,tt1907668  \n",
       "3  tt0101410,tt1179933,tt1024648,tt1907668  \n",
       "4  tt0101410,tt1179933,tt1024648,tt1907668  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open movie data set\n",
    "moviedata = pd.read_csv(DATA_DIR + MOVIE_DATASET)\n",
    "moviedata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some categories, if not we would have\n",
    "# e.g. Joe Biden as an actor because of an archive footage\n",
    "\n",
    "# Remove archive movies\n",
    "moviedata = moviedata[moviedata[\"category\"] != \"archive_footage\"]\n",
    "# Remove biopics (movies where the actors is his own character)\n",
    "moviedata = moviedata[moviedata[\"characters\"] != \"[\\\"Self\\\"]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the code separately for each year of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the given year's quotes and filters those whose speaker is in the movie dataset\n",
    "# (whether it's an actor, the director, or any other)\n",
    "def handleYear(year):\n",
    "    # We read the dataset by chunks because it is too big\n",
    "    # Warning: it takes a long time\n",
    "    with pd.read_json(DATA_DIR + quotes_dataset(year), lines=True, chunksize=10000) as df_reader:\n",
    "\n",
    "        # Concatenate the quotes whose speaker are in the movie dataset\n",
    "        quotes = pd.DataFrame()\n",
    "        # Use tqdm to display a progress bar (it takes a long time)\n",
    "        pbar = tqdm(df_reader)\n",
    "        for chunk in pbar:\n",
    "            quotes = pd.concat((quotes,chunk[chunk[\"speaker\"].isin(moviedata[\"primaryName\"])]))\n",
    "            pbar.set_description(f\"({year}) Number of quotes extracted = {quotes.shape[0]}\")\n",
    "\n",
    "    print(f\"Year {year}: {quotes.shape[0]} quotes extracted\")\n",
    "    #quotes.head()\n",
    "    \n",
    "    # Save to the data folder\n",
    "    quotes.to_csv(DATA_DIR + output_dataset(year), compression='gzip')\n",
    "    \n",
    "    # Display the speakers and their citation count, in descending order\n",
    "    # (just to check)\n",
    "    #quotes.groupby(\"speaker\").agg(count=(\"speaker\",\"count\")).sort_values([\"count\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all jobs in parallel\n",
    "# The progress bars don't render well but it's better than nothing.\n",
    "# (and specifying a position for the bars doesn't renders well either)\n",
    "\n",
    "jobs = []\n",
    "for year in YEARS:\n",
    "    job = multiprocessing.Process(target=lambda: handleYear(year))\n",
    "    jobs.append(job)\n",
    "    job.start()\n",
    "\n",
    "# Wait for each job to finish.\n",
    "for job in jobs:\n",
    "    job.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the columns related to the crew and other uninteresting columns.\n",
    "moviedata.drop(['Unnamed: 0', 'startYear', 'endYear', 'titleType', 'nconst', 'category', 'job', 'characters', 'primaryName', 'birthYear', 'deathYear', 'primaryProfession', 'knownForTitles'], axis=1, inplace=True)\n",
    "# Only keep one row per movie.\n",
    "moviedata.drop_duplicates(subset=\"tconst\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the gross value as an integer, to compare movies easily.\n",
    "moviedata['Total Gross'] = moviedata['Total Gross'].map(lambda x: int(x[1:].replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode VII - The Force Awakens',\n",
       " 'Avengers: Endgame',\n",
       " 'Black Panther',\n",
       " 'Avengers: Infinity War',\n",
       " 'Jurassic World',\n",
       " 'Star Wars: Episode VIII - The Last Jedi',\n",
       " 'Incredibles 2',\n",
       " 'The Lion King',\n",
       " 'Rogue One: A Star Wars Story',\n",
       " 'Star Wars: Episode IX - The Rise of Skywalker',\n",
       " 'Beauty and the Beast',\n",
       " 'Finding Dory',\n",
       " 'Frozen II',\n",
       " 'Avengers: Age of Ultron',\n",
       " 'Toy Story 4',\n",
       " 'Captain Marvel',\n",
       " 'Jurassic World: Fallen Kingdom',\n",
       " 'Wonder Woman',\n",
       " 'Captain America: Civil War',\n",
       " 'Jumanji: Welcome to the Jungle',\n",
       " 'Spider-Man: Far from Home',\n",
       " 'Guardians of the Galaxy Vol. 2',\n",
       " 'The Secret Life of Pets',\n",
       " 'The Jungle Book',\n",
       " 'Deadpool',\n",
       " 'Inside Out',\n",
       " 'Aladdin',\n",
       " 'Furious 7',\n",
       " 'American Sniper',\n",
       " 'Zootopia',\n",
       " 'The Hunger Games: Mockingjay - Part 1',\n",
       " 'Minions',\n",
       " 'Joker',\n",
       " 'Aquaman',\n",
       " 'Spider-Man: Homecoming',\n",
       " 'Batman v Superman: Dawn of Justice',\n",
       " 'It',\n",
       " 'Suicide Squad',\n",
       " 'Jumanji: The Next Level',\n",
       " 'Deadpool 2',\n",
       " 'Thor: Ragnarok',\n",
       " 'The Hunger Games: Mockingjay - Part 2',\n",
       " 'The Grinch',\n",
       " 'Sing',\n",
       " 'Despicable Me 3',\n",
       " 'The Hobbit: The Battle of the Five Armies',\n",
       " 'Moana',\n",
       " 'Fantastic Beasts and Where to Find Them',\n",
       " 'Doctor Strange',\n",
       " 'Justice League']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first 20 movies ranked by their box-office results.\n",
    "moviedata.sort_values('Total Gross', ascending=False).head(50)[\"primaryTitle\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of movie titles with their patterns to look for in the quotes\n",
    "# (if a given pattern is found, it is considered that the quote mentions the movie)\n",
    "alttitles = [\n",
    "    ('Star Wars: Episode VII - The Force Awakens', ['Star Wars', 'The force awakens']),\n",
    "    ('Avengers: Endgame', ['Avengers', 'Endgame']),\n",
    "    ('Black Panther', ['Black Panther']),\n",
    "    ('Avengers: Infinity War', ['Infinity War', 'Avengers']),\n",
    "    ('Jurassic World', ['Jurassic']), # Probably a bad idea but let's see\n",
    "    ('Star Wars: Episode VIII - The Last Jedi', ['Star Wars', 'Last Jedi']),\n",
    "    ('Incredibles 2', ['Incredibles']), # Possibly too broad\n",
    "    ('The Lion King', ['Lion King']),\n",
    "    ('Rogue One: A Star Wars Story', ['Rogue One', 'Star Wars']),\n",
    "    ('Star Wars: Episode IX - The Rise of Skywalker', ['Star Wars', 'Skywalker']),\n",
    "    ('Beauty and the Beast', ['Beauty and the Beast']),\n",
    "    ('Finding Dory', ['Finding Dory']),\n",
    "    ('Frozen II', ['Frozen']), # Probably a bad idea but let's see\n",
    "    ('Avengers: Age of Ultron', ['Avengers', 'Ultron']),\n",
    "    ('Toy Story 4', ['Toy Story']),\n",
    "    ('Captain Marvel', ['Marvel']),\n",
    "    ('Jurassic World: Fallen Kingdom', ['Jurassic', 'Fallen Kingdom']),\n",
    "    ('Captain America: Civil War', ['Captain America', 'Civil War']),\n",
    "    ('Jumanji: Welcome to the Jungle', ['Jumanji', 'Welcome to the Jungle']),\n",
    "    #('Spider-Man: Far from Home', ['Spider-Man', 'Spider Man', 'Far from Home']),\n",
    "    ('Guardians of the Galaxy Vol. 2', ['Guardians of the Galaxy']),\n",
    "    ('The Secret Life of Pets', ['Secret Life of Pets']),\n",
    "    ('The Jungle Book', ['Jungle Book']),\n",
    "    ('Deadpool', ['Deadpool']),\n",
    "    ('Inside Out', ['Inside Out']),\n",
    "    ('Aladdin', ['Aladdin']),\n",
    "    ('Furious 7', ['Furious']), # Probably a bad idea but let's see\n",
    "    ('American Sniper', ['American Sniper']),\n",
    "    ('Zootopia', ['Zootopia']),\n",
    "    ('The Hunger Games: Mockingjay - Part 1', ['Hunger Games', 'Mockingjay']),\n",
    "    ('Minions', ['Minions']), # Possibly too broad\n",
    "    ('Joker', ['Joker']),\n",
    "    ('Aquaman', ['Aquaman']),\n",
    "    ('Spider-Man: Homecoming', ['Spider-Man', 'Spider Man', 'Homecoming']),\n",
    "    ('Batman v Superman: Dawn of Justice', ['Batman', 'Superman', 'Dawn of Justice']),\n",
    "    #('It', []), # just not possible\n",
    "    ('Suicide Squad', ['Suicide Squad']),\n",
    "    ('Jumanji: The Next Level', ['Jumanji', 'The Next Level']),\n",
    "    ('Deadpool 2', ['Deadpool']),\n",
    "    ('Thor: Ragnarok', ['Thor', 'Ragnarok']),\n",
    "    ('The Hunger Games: Mockingjay - Part 2', ['Hunger Games', 'Mockingjay']),\n",
    "    ('The Grinch', ['Grinch']),\n",
    "    ('Sing', ['Sing']), # Probably a bad idea but let's see\n",
    "    ('Despicable Me 3', ['Despicable Me']),\n",
    "    ('The Hobbit: The Battle of the Five Armies', ['Hobbit', 'Battle of the Five Armies']),\n",
    "    ('Moana', ['Moana']),\n",
    "    ('Fantastic Beasts and Where to Find Them', ['Fantastic Beasts']),\n",
    "    ('Doctor Strange', ['Doctor Strange']),\n",
    "    ('Justice League', ['Justice League'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full release date as a datetime\n",
    "moviedata[\"release\"] = moviedata[\"Release Date\"] + \" \" + moviedata[\"Year\"].astype(int).astype(str)\n",
    "moviedata[\"release\"] = pd.to_datetime(moviedata[\"release\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the years which are within the timedelta of the release of the movie.\n",
    "# timedelta must be less than one year, for convenience.\n",
    "def get_years(movie, timedelta):\n",
    "    row = moviedata[moviedata[\"primaryTitle\"] == movie].iloc[0]\n",
    "    release = row[\"release\"]\n",
    "    year = int(row[\"Year\"])\n",
    "    years = [year]\n",
    "    if release - datetime.datetime(year, 1, 1) < timedelta:\n",
    "        years.append(year-1)\n",
    "    if datetime.datetime(year, 12, 31) - release < timedelta:\n",
    "        years.append(year+1)\n",
    "    years = filter(lambda y: END_YEAR >= y >= START_YEAR, years)\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the list of quotes that mention one of the titles, and that\n",
    "# are within the time delta of the release date of the movie.\n",
    "# timedelta must be less than one year. \n",
    "def findQuotes(movie, titles, timedelta, export=True):\n",
    "    years = get_years(movie, timedelta)\n",
    "    quotes = pd.DataFrame()\n",
    "    row = moviedata[moviedata[\"primaryTitle\"] == movie].iloc[0]\n",
    "    release = row[\"release\"]\n",
    "    \n",
    "    # Generate the regex that will be searched to match the movie\n",
    "    titleregex = \"|\".join(titles)\n",
    "\n",
    "    def valid_date(quotedate):\n",
    "        return release - timedelta < quotedate[\"date\"] < release + timedelta \n",
    "    \n",
    "    for year in years:\n",
    "        with pd.read_json(DATA_DIR + quotes_dataset(year), lines=True, chunksize=100000) as df_reader:\n",
    "            pbar = tqdm(df_reader)\n",
    "            count = 0\n",
    "            for chunk in pbar:\n",
    "                count += len(chunk)\n",
    "                pbar.set_description(f\"{movie} / {year}: progress = {count}\")\n",
    "                \n",
    "                # Fast filter of the chunk, but works only if the quote dataset is sorted!\n",
    "                # (which it is not for now, but if we need to extract the quotes for lots of movie\n",
    "                # it would be convenient to sort them)\n",
    "                #if not valid_date(chunk.iloc[0]) and not valid_date(chunk.iloc[len(chunk)-1]):\n",
    "                #    continue\n",
    "                \n",
    "                # filter by dates\n",
    "                chunk = chunk[(chunk[\"date\"] > release - timedelta) & (chunk[\"date\"] < release + timedelta)]\n",
    "                # filter those containing one of the titles\n",
    "                chunk = chunk[chunk[\"quotation\"].str.contains(titleregex, na=False, case=False, regex=True)]\n",
    "                # append the selected quotes\n",
    "                quotes = pd.concat((quotes, chunk))\n",
    "\n",
    "            print(f\"{movie} / {year}: {quotes.shape[0]} quotes extracted\")\n",
    "            #quotes.head()\n",
    "\n",
    "    # Specify the movie\n",
    "    quotes[\"primaryTitle\"] = movie\n",
    "    \n",
    "    if export:\n",
    "        # Save to the data folder\n",
    "        quotes.to_csv(DATA_DIR + \"movies/\" + movie + \".csv.gz\", compression='gzip')\n",
    "    else:\n",
    "        return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1: start\n",
      "Thread 2: startThread 1: processing American Sniper\n",
      "\n",
      "Thread 3: startThread 2: processing Aladdin\n",
      "\n",
      "Thread 4: start\n",
      "Thread 3: processing Inside OutThread 5: startThread 4: processing Deadpool\n",
      "\n",
      "\n",
      "Thread 5: processing The Jungle BookThread 6: start\n",
      "\n",
      "\n",
      "Thread 7: startThread 6: processing The Secret Life of Pets\n",
      "Thread 7: processing Guardians of the Galaxy Vol. 2\n",
      "Thread 8: start\n",
      "Thread 8: processing Jumanji: Welcome to the Jungle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deadpool / 2016: progress = 13862129: : 139it [26:11, 11.31s/it]t]t [26:10, 12.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadpool / 2016: 668 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Jungle Book / 2016: progress = 13862129: : 139it [26:15, 11.34s/it].11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Jungle Book / 2016: 211 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Secret Life of Pets / 2016: progress = 13862129: : 139it [26:33, 11.47s/it]08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Secret Life of Pets / 2016: 38 quotes extracted\n",
      "Thread 6: processing Captain America: Civil War\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "American Sniper / 2015: progress = 20874338: : 209it [37:36, 10.79s/it]0.20s/it]1s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Sniper / 2015: 49 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inside Out / 2015: progress = 20874338: : 209it [37:50, 10.87s/it]t [37:49, 12.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Out / 2015: 1233 quotes extracted\n",
      "Thread 3: processing Wonder Woman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aladdin / 2019: progress = 21763302: : 218it [40:59, 11.28s/it]it]21, 10.11s/it]0s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aladdin / 2019: 681 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captain America: Civil War / 2016: progress = 13862129: : 139it [23:25, 10.11s/it]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain America: Civil War / 2016: 3562 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardians of the Galaxy Vol. 2 / 2017: progress = 26611588: : 267it [54:59, 12.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardians of the Galaxy Vol. 2 / 2017: 841 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jumanji: Welcome to the Jungle / 2017: progress = 26611588: : 267it [55:14, 12.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumanji: Welcome to the Jungle / 2017: 203 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deadpool / 2015: progress = 20874338: : 209it [34:09,  9.24s/it]79s/it]1, 10.06s/it]\n",
      "Deadpool / 2015: progress = 20874338: : 209it [34:09,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadpool / 2015: 935 quotes extracted\n",
      "The Jungle Book / 2015: 227 quotes extracted\n",
      "Thread 5: processing Jurassic World: Fallen Kingdom\n",
      "Thread 4: processing Captain Marvel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "American Sniper / 2016: progress = 13862129: : 139it [23:13, 10.02s/it]2, 10.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Sniper / 2016: 62 quotes extracted\n",
      "Thread 1: processing Toy Story 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardians of the Galaxy Vol. 2 / 2016: progress = 13862129: : 139it [23:10, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardians of the Galaxy Vol. 2 / 2016: 906 quotes extracted\n",
      "Thread 7: processing Avengers: Age of Ultron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captain America: Civil War / 2015: progress = 20874338: : 209it [33:31,  9.62s/it]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain America: Civil War / 2015: 4598 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Avengers: Age of Ultron / 2015: progress = 3100000: : 31it [05:20, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 6: processing Frozen II\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aladdin / 2018: progress = 27228451: : 273it [47:35, 10.46s/it]24, 10.15s/it]0.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aladdin / 2018: 760 quotes extracted\n",
      "Thread 2: processing Finding Dory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wonder Woman / 2017: progress = 26611588: : 267it [52:10, 11.72s/it]t]9:38, 10.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonder Woman / 2017: 3143 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captain Marvel / 2019: progress = 21763302: : 218it [36:49, 10.14s/it]0.07s/it]92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain Marvel / 2019: 8512 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom / 2018: progress = 20400000: : 204it [36:51, 10.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story 4 / 2019: 513 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jumanji: Welcome to the Jungle / 2018: progress = 27228451: : 273it [49:43, 10.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumanji: Welcome to the Jungle / 2018: 365 quotes extracted\n",
      "Thread 8: processing Beauty and the Beast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom / 2018: progress = 27228451: : 273it [49:06, 10.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom / 2018: 1136 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Dory / 2016: progress = 13862129: : 139it [23:17, 10.05s/it]  9.99s/it]s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Dory / 2016: 73 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wonder Woman / 2016: progress = 13862129: : 139it [22:46,  9.83s/it]7s/it]11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonder Woman / 2016: 3227 quotes extracted\n",
      "Thread 3: processing Star Wars: Episode IX - The Rise of Skywalker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron / 2015: progress = 20874338: : 209it [35:21, 10.15s/it][00:42, 10.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron / 2015: 1574 quotes extracted\n",
      "Thread 7: processing Rogue One: A Star Wars Story\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frozen II / 2019: progress = 21763302: : 218it [36:32, 10.06s/it]s/it], 10.61s/it]t]:06, 10.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen II / 2019: 2581 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frozen II / 2020: progress = 5244449: : 53it [09:48, 11.11s/it]08s/it], 12.18s/it]16:58, 11.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen II / 2020: 3720 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Toy Story 4 / 2018: progress = 18200000: : 182it [32:38, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 6: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rogue One: A Star Wars Story / 2016: progress = 13862129: : 139it [25:24, 10.97s/it]26:03, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue One: A Star Wars Story / 2016: 2514 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Toy Story 4 / 2018: progress = 27228451: : 273it [48:16, 10.61s/it]it]000: : 184it [32:41, 10.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story 4 / 2018: 514 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Captain Marvel / 2018: progress = 27200000: : 272it [48:18, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captain Marvel / 2018: progress = 27228451: : 273it [48:21, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain Marvel / 2018: 12145 quotes extracted\n",
      "Thread 4: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Dory / 2015: progress = 20874338: : 209it [34:19,  9.85s/it]00000: : 189it [33:22,  8.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Dory / 2015: 76 quotes extracted\n",
      "Thread 2: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Star Wars: Episode IX - The Rise of Skywalker / 2019: progress = 21763302: : 218it [36:56, 10.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars: Episode IX - The Rise of Skywalker / 2019: 3156 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beauty and the Beast / 2017: progress = 26611588: : 267it [49:07, 11.04s/it]4s/it]04:17,  7.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beauty and the Beast / 2017: 592 quotes extracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom / 2017: progress = 26611588: : 267it [46:34, 10.47s/it]5,  7.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom / 2017: 1148 quotes extracted\n",
      "Thread 5: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Star Wars: Episode IX - The Rise of Skywalker / 2020: progress = 5244449: : 53it [06:32,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars: Episode IX - The Rise of Skywalker / 2020: 4038 quotes extracted\n",
      "Thread 3: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beauty and the Beast / 2016: progress = 13862129: : 139it [13:24,  5.79s/it].74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beauty and the Beast / 2016: 640 quotes extracted\n",
      "Thread 8: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rogue One: A Star Wars Story / 2017: progress = 26611588: : 267it [33:57,  7.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue One: A Star Wars Story / 2017: 4425 quotes extracted\n",
      "Thread 7: done\n"
     ]
    }
   ],
   "source": [
    "# Beware: take a looooong time, even with 8 threads, in my case 6~7h for 48 movies\n",
    "# A possible faster way would be to split the years among\n",
    "# the threads to avoid reading several times the dataset (considering\n",
    "# that reading from disk is the bottleneck, and not comparing strings)\n",
    "# or to sort the dataset to ignore chunks directly\n",
    "\n",
    "# For each movie in the alttitles dictionnary, find the quotes that mention this movie\n",
    "# within the given time delta of the release date.\n",
    "timedelta = datetime.timedelta(weeks=25)\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "# Use a shared list, that will be used to split the workload amongst threads\n",
    "movies = manager.list()\n",
    "for mov in alttitles:\n",
    "    movies.append(mov)\n",
    "\n",
    "# While there are movies in `movies` to process, pop one and look for its quotes\n",
    "def worker(threadnum):\n",
    "    print(f\"Thread {threadnum+1}: start\")\n",
    "    try:\n",
    "        while True:\n",
    "            movie, titles = movies.pop()\n",
    "            print(f\"Thread {threadnum+1}: processing {movie}\")\n",
    "            findQuotes(movie, titles, timedelta)\n",
    "    except IndexError:\n",
    "        # The list is empty\n",
    "        print(f\"Thread {threadnum+1}: done\")\n",
    "        return\n",
    "\n",
    "jobs = []\n",
    "# Start 8 threads which will, for each movie, find its quotes\n",
    "for threadnum in range(8):\n",
    "    job = multiprocessing.Process(target=lambda: worker(threadnum))\n",
    "    jobs.append(job)\n",
    "    job.start()\n",
    "\n",
    "# Wait for each job to finish.\n",
    "for job in jobs:\n",
    "    job.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all produced datasets into one\n",
    "allquotes = pd.DataFrame()\n",
    "for movie, _ in alttitles:\n",
    "    quotes = pd.read_csv(DATA_DIR + \"movies/\" + movie + \".csv.gz\")\n",
    "    #print(movie, quotes.shape[0])\n",
    "    allquotes = pd.concat((allquotes, quotes))\n",
    "\n",
    "allquotes.to_csv(DATA_DIR + \"50moviesquotes.csv.gz\", compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "535feb9148a04feb856e0fc880ebc8e4dd5554d5a3f65f80ac0547368bdbd739"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
